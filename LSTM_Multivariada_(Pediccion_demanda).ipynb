{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "###- TESIS Constanza Gaset\n",
        "# Mayo 2022\n",
        "# UNIVERSIDAD TORCUATO DI TELLA\n",
        "# REDES NEURONALES RECURRENTES APLICADAS A SERIES DE TIEMPO: PREDICCIÓN DE PASAJEROS DE RUTAS REGIONALES EN ARGENTINA"
      ],
      "metadata": {
        "id": "vWYyOgyOuHPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comenzamos con las configuraciones generales y las librerías a utilizar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas.plotting import register_matplotlib_converters %matplotlib inline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ],
      "metadata": {
        "id": "OAZCMCyEtLm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seteamos del espacio de trabajo, en este caso, un espacio local\n",
        "os.getcwd()\n",
        "os.chdir('C:/Users/Desktop/)"
      ],
      "metadata": {
        "id": "Rfu7kNiatqAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyXi6TinqXWc"
      },
      "outputs": [],
      "source": [
        "### RED LSTM MULTIVARIADA\n",
        "# Este proceso se realiza para las 11 rutas bajo análisis.\n",
        "# Se replica para el año 2020 (como horizonte de proyección), utilizando como entrenamiento 2001 a 2018 y prueba 2019 a 2020.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Preprocesamiento de los datos\n",
        "# Cargamos el dataset, previamente transformado, a nivel ruta, para las 11 rutas en análisis. Se agregaron también los datos de evolución del tipo de cambio y EMAE\n",
        "df_BUEXXX_lstm_multiv=pd.read_excel('Database.xlsx', heet_name='Dataset_Multiv_BUEXXX', indexcol=0)\n"
      ],
      "metadata": {
        "id": "pdmeM4srq0TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la red multivariada filtramos los datos, quedándonos con las observaciones desde 2004 a 2021\n",
        "df_BUEXXX_lstm_multiv=df_BUEXXX_lstm_multiv.iloc[:216,1:]"
      ],
      "metadata": {
        "id": "9I1UrNwaq4bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos los datasets de entrenamiento y prueba: 2001-2019 entrenamiento y 2020-2021 prueba train_size= 192\n",
        "train_BUEXXX_lstm_multiv,test_BUEXXX_lstm_multiv=df_BUEXXX_lstm_mult iv.iloc[0:train_size], df_BUEXXX_lstm_multiv.iloc[train_size:len(df_BUEXXX)]"
      ],
      "metadata": {
        "id": "evb2FyW-q61-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Revisamos que los datos hayan quedado correctamente separados\n",
        "print(len(train_BUEXXX_lstm_multiv), len(test_BUEXXX_lstm_multiv)) print(train_BUEXXX_lstm_multiv) print(test_BUEXXX_lstm_multiv)"
      ],
      "metadata": {
        "id": "zScy_iz2rDeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalamos los datos entre 0 y 1 con MinMaxScaler\n",
        "f_columns = ['Vuelos_BUEXXX', 'TC', 'EMAE']\n",
        "f_col_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "pax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "train_BUEXXX_lstm_multiv.loc[:,f_columns]=f_col_scaler.fit_transform(train_BUEXXX_lstm_multiv[f_columns])\n",
        "train_BUEXXX_lstm_multiv['Pax_BUEXXX']=pax_scaler.fit_transform(train_BUEXXX_lstm_multiv[['Pax_BUEXXX']])\n",
        "\n",
        "test_BUEXXX_lstm_multiv.loc[:,f_columns]=f_col_scaler.fit_transform(test_BUEXXX_lstm_multiv[f_columns]) test_BUEXXX_lstm_multiv['Pax_BUEXXX']=pax_scaler.fit_transform(test_ BUEXXX_lstm_multiv[['Pax_BUEXXX']])"
      ],
      "metadata": {
        "id": "B_UGlRG5rEIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisamos que los datos hayan quedado correctamente convertidos\n",
        "print(train_BUEXXX_lstm_multiv)\n",
        "print(test_BUEXXX_lstm_multiv)"
      ],
      "metadata": {
        "id": "-Ehmb_DnrKkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparamos la información para la red neuronal con la función create_dataset. A partir de esta función creamos secuencias de datos, definidas por los time steps definidos\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "Xs, ys = [], []\n",
        "for i in range(len(X) - time_steps):\n",
        "    v = X.iloc[i:(i + time_steps)].values\n",
        "    Xs.append(v)\n",
        "    ys.append(y.iloc[i + time_steps])\n",
        "return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "dF97XAzdrN9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos el reshape aplicando la función, llevamos los datos a un formato [muestras, pasos del tiempo, características]\n",
        "time_steps = 12\n",
        "X_train_BUEXXX_lstm_multiv,y_train_BUEXXX_lstm_multiv=create_dataset (train_BUEXXX_lstm_multiv, train_BUEXXX_lstm_multiv.BUEXXX,time_steps)\n",
        "X_test_BUEXXX_lstm_multiv,y_test_BUEXXX_lstm_multiv=create_dataset(t est_BUEXXX_lstm_multiv, test_BUEXXX_lstm_multiv.BUEXXX, time_steps)"
      ],
      "metadata": {
        "id": "m2jKNWXzrVqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corroboramos que la información es correcta\n",
        "print(X_train_BUEXXX_lstm_multiv.shape, y_train_BUEXXX_lstm_multiv.shape)\n",
        "print(X_test_BUEXXX_lstm_multiv.shape, y_test_BUEXXX_lstm_multiv.shape)"
      ],
      "metadata": {
        "id": "VPHIPfRirba7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observamos las secuencias creadas para entrenamiento y testeo\n",
        "X_train_BUEXXX_lstm_multiv[0]\n",
        "y_train_BUEXXX_lstm_multiv[0]\n",
        "X_train_BUEXXX_lstm_multiv[1] y_train_BUEXXX_lstm_multiv[1]"
      ],
      "metadata": {
        "id": "j-ZdEp6urgu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Modelado\n",
        "# Definimos el modelo a utilizar: red neuronal LSTM secuencial con 1 capa oculta y 100 neuronas, función de perdida entropía cruzada y función de optimización Adam con learning rate 0.01\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(units=100,\n",
        "input_shape=(X_train_BUEXXX_lstm_multiv.shape[1], X_train_BUEXXX_lstm_multiv.shape[2])))\n",
        "model.add(keras.layers.Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(0.01))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BXJyMtdLrkad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Entrenamiento del modelo\n",
        "# Para el entrenamiento se definen 100 épocas y tamaño de lote de 42\n",
        "\n",
        "history_BUEXXX_lstm_multiv = model.fit(\n",
        "      X_train_BUEXXX_lstm_multiv, y_train_BUEXXX_lstm_multiv,\n",
        "      epochs=100,\n",
        "      batch_size=42,\n",
        "      verbose=1,\n",
        "      shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "Db1e-IP_rrJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos la perdida en entrenamiento y testeo\n",
        "plt.plot(history_BUEXXX_lstm_multiv.history['loss'], label='train')\n",
        "plt.plot(history_BUEXXX_lstm_multiv.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XySDFS2KruU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Evaluación del modelo\n",
        "# Hacemos las proyecciones con el modelo entrenado\n",
        "y_pred_BUEXXX_lstm_multiv = model.predict(X_test_BUEXXX_lstm_multiv)"
      ],
      "metadata": {
        "id": "-ED-SCU2r3Fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}